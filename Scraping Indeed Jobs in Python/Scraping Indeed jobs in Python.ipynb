{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Indeed jobs in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following notebook demonstrates simple way to scrap jobs data from website named indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief about <b>Web scraping</b>: \n",
    "Web scraping is data scraping used for extracting data from websites. Web scraping software may access the World Wide Web directly using the Hypertext Transfer Protocol, or through a web browser.\n",
    "\n",
    "Source: <a href=\"https://en.wikipedia.org/wiki/Web_scraping\">Wikipedia</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need following libraries of Python: requests, html5lib, bs4(Beautiful Soup 4). You can install them using the pip package manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first import all the libraries that we will use in this scraping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scraping data from the website, first we need their HTML data which we can get by a request from their server. Hence we can get the HTML data by passing a URL to get method of requests library. But depending upon the company you're searching for, the URL will be different. So for that, let us closely examing the URL mapping of a search in Indeed website. \n",
    "\n",
    "As you can see in the image below, when you search for Goldman Sachs jobs, the parameter \"q\" in URL is set equal to the keywords user typed in the search query. The spaces in the search query are ignored and the individual words of the query are concatenated. Also, the parameter \"l\" is responsible for collecting the location query of the user who is searching. Therefore, using string manipulation, we can generate URLs for any search done based on the keywords in the query.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"url.jpg\" alt=\"An image unavailable\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity and demonstration purposes, let us search for first few jobs with keywords \"goldman sachs\", same as mentioned in the above image.\n",
    "\n",
    "Therefore, we create the URL accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"https://www.indeed.co.in/jobs?q=goldman+sachs&l=\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our URL ready, for getting the HTML data, we will pass the URL to get method provided by the requests library and pass the response of that method to BeautifulSoup constructor, so that we can get the raw HTML content.\n",
    "\n",
    "<pre>\n",
    "BeautifulSoup constructor parameters:\n",
    "req.content ==> The raw HTML content sent as a response.\n",
    "html5lib ==> HTML parser to be used for parsing HTML data.\n",
    "</pre>\n",
    "\n",
    "An HTML parser parses the raw HTML content and constructs it in the form of HTML tree hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = requests.get(URL)\n",
    " \n",
    "htmlData = BeautifulSoup(req.content, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the HTML structured data, we will use the robust BeautifulSoup library to go to each section of the HTML and get the things we need. We're scraping the job titles and their location of the few jobs posted on the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobtitles = []\n",
    "joblocation = []\n",
    "\n",
    "for table in htmlData.find_all(name='table' , attrs={'id':'resultsBody'}):\n",
    "    for table1 in htmlData.find_all(name='table' , attrs={'id':'pageContent'}):\n",
    "        for td in table.find_all(name='td' , attrs={'id':'resultsCol'}):\n",
    "            for div in td.find_all(name='div' , attrs={'data-tn-component':'organicJob'}):\n",
    "                for h2 in div.find_all(name='h2', attrs={'class':'jobtitle'}):\n",
    "                    for a in h2.find_all(name='a', attrs={'class':'turnstileLink'}):\n",
    "                        jobtitles.append(a['title'])\n",
    "\n",
    "for table in htmlData.find_all(name='table' , attrs={'id':'resultsBody'}):\n",
    "    for table1 in htmlData.find_all(name='table' , attrs={'id':'pageContent'}):\n",
    "        for td in table.find_all(name='td' , attrs={'id':'resultsCol'}):\n",
    "            for div in td.find_all(name='div' , attrs={'data-tn-component':'organicJob'}):\n",
    "                for span in div.find_all(name='span', attrs={'class':'location'}):\n",
    "                    joblocation.append(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, what we did is we manually inspected the HTML content using an Inspector available in a browser. Then from that, we have an overall idea how the content we are interested in ie. the job postings are saved. Then we simply dive into each hierarchies of the tags and sections, to obtain the desired data and store it an array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the data which is needed, is available and what's left is simply to arrange it in a format and print the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goldman Sachs jobs by Indeed:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Research &amp; Development Engineering - Software ...</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technology Risk - Risk Measurement &amp; Analytics...</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Platform - Application Infrastructure - Develo...</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Finance - Controllers - Regulatory Capital &amp; R...</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technology Risk - Risk Measurement &amp; Analytics...</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marquee Engineering - Software Engineer</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Finance - Investment Management Division - Pri...</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Securities- Equities One Infra Strats - Analys...</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Platform - App Bank Operation - Front Line Sup...</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Platform - Foundational Engg - DDI Engineer</td>\n",
       "      <td>Bengaluru, Karnataka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title              Location\n",
       "0  Research & Development Engineering - Software ...                 India\n",
       "1  Technology Risk - Risk Measurement & Analytics...  Bengaluru, Karnataka\n",
       "2  Platform - Application Infrastructure - Develo...  Bengaluru, Karnataka\n",
       "3  Finance - Controllers - Regulatory Capital & R...  Bengaluru, Karnataka\n",
       "4  Technology Risk - Risk Measurement & Analytics...  Bengaluru, Karnataka\n",
       "5            Marquee Engineering - Software Engineer                 India\n",
       "6  Finance - Investment Management Division - Pri...  Bengaluru, Karnataka\n",
       "7  Securities- Equities One Infra Strats - Analys...  Bengaluru, Karnataka\n",
       "8  Platform - App Bank Operation - Front Line Sup...                 India\n",
       "9        Platform - Foundational Engg - DDI Engineer  Bengaluru, Karnataka"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlesSeries = Series(np.array(jobtitles))\n",
    "locationSeries = Series(np.array(joblocation))\n",
    "dataframe = pd.concat([titlesSeries,locationSeries],axis=1)\n",
    "dataframe.columns = ['Job Title','Location']\n",
    "print(\"Goldman Sachs jobs by Indeed:\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we have some job postings at Goldman Sachs from indeed.com.\n",
    "\n",
    "Let us try some other company along with the location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morgan Stanley Mumbai jobs by Indeed:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analyst - Risk Identification</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Risk Analytics</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scenario Analytics Associate/Analyst</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyst - ICAAP Production</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Associate GGLC</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analyst - Cash Client Processing</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate - Payment Investigation, SSBO</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSDE Engineer</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Developer - Database</td>\n",
       "      <td>Mumbai, Maharashtra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job Title             Location\n",
       "0                                Associate  Mumbai, Maharashtra\n",
       "1            Analyst - Risk Identification  Mumbai, Maharashtra\n",
       "2                 Associate Risk Analytics  Mumbai, Maharashtra\n",
       "3     Scenario Analytics Associate/Analyst  Mumbai, Maharashtra\n",
       "4               Analyst - ICAAP Production  Mumbai, Maharashtra\n",
       "5                           Associate GGLC  Mumbai, Maharashtra\n",
       "6         Analyst - Cash Client Processing  Mumbai, Maharashtra\n",
       "7  Associate - Payment Investigation, SSBO  Mumbai, Maharashtra\n",
       "8                            MSDE Engineer  Mumbai, Maharashtra\n",
       "9                     Developer - Database  Mumbai, Maharashtra"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://www.indeed.co.in/jobs?q=morgan+stanley&l=mumbai\"\n",
    "req = requests.get(URL)\n",
    "htmlData = BeautifulSoup(req.content, 'html5lib')\n",
    "\n",
    "jobtitles = []\n",
    "joblocation = []\n",
    "\n",
    "for table in htmlData.find_all(name='table' , attrs={'id':'resultsBody'}):\n",
    "    for table1 in htmlData.find_all(name='table' , attrs={'id':'pageContent'}):\n",
    "        for td in table.find_all(name='td' , attrs={'id':'resultsCol'}):\n",
    "            for div in td.find_all(name='div' , attrs={'data-tn-component':'organicJob'}):\n",
    "                for h2 in div.find_all(name='h2', attrs={'class':'jobtitle'}):\n",
    "                    for a in h2.find_all(name='a', attrs={'class':'turnstileLink'}):\n",
    "                        jobtitles.append(a['title'])\n",
    "\n",
    "for table in htmlData.find_all(name='table' , attrs={'id':'resultsBody'}):\n",
    "    for table1 in htmlData.find_all(name='table' , attrs={'id':'pageContent'}):\n",
    "        for td in table.find_all(name='td' , attrs={'id':'resultsCol'}):\n",
    "            for div in td.find_all(name='div' , attrs={'data-tn-component':'organicJob'}):\n",
    "                for span in div.find_all(name='span', attrs={'class':'location'}):\n",
    "                    joblocation.append(span.text)\n",
    "                    \n",
    "titlesSeries = Series(np.array(jobtitles))\n",
    "locationSeries = Series(np.array(joblocation))\n",
    "dataframe = pd.concat([titlesSeries,locationSeries],axis=1)\n",
    "dataframe.columns = ['Job Title','Location']\n",
    "print(\"Morgan Stanley Mumbai jobs by Indeed:\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have scraped jobs at Morgan Stanley in Mumbai.\n",
    "\n",
    "Hence, a simple web scraper for scraping jobs from Indeed is designed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks for reading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
